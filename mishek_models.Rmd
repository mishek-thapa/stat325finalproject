---
title: "Mishek's Models"
output: pdf_document
---

```{r}
knitr::opts_chunk$set(message = FALSE, echo = FALSE, warning=FALSE)
```

```{r}
library(tidyverse)
library(glmnet)
library(mgcv)
library(visreg)
library(mgcViz)
library(caret)
library(leaps)
library(MASS)
```


# Lasso 
```{r}
mydata <- read_csv("covid.csv") 


 #remove covid case count and remove the death count?
mydata <- mydata %>%
  dplyr::select(-c(1:4,29:31)) 


mydata <- mydata[is.finite(mydata$covid_death_rate_log),]
```


```{r}
x <- model.matrix(covid_death_rate_log~.,mydata)[,-1]
y <- mydata$covid_death_rate_log 
grid <- 10^seq(10, -2, length = 100) # grid of values for lambda parameters
```


```{r}
set.seed(17)
train <- sample(1:nrow(x), nrow(x)*0.7)
test <- (-train)
y.test <- y[test]

#dataframes
train_data <- mydata[train, ]
test_data <- mydata[-c(train), ]
```

```{r}
lasso.mod <- glmnet(x[train,], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
```

```{r}
set.seed(1)
cv.out <- cv.glmnet(x[train,], y[train], alpha = 1, )
plot(cv.out)
bestlam <- cv.out$lambda.min
```

```{r}
lasso.pred <- predict(lasso.mod, s = bestlam, newx = x[test,])
mean((lasso.pred - y.test)^2)
```


```{r}
out <- glmnet(x, y, alpha = 1, lambda = grid)
lasso.coef <- predict(out, type = "coefficients", s = bestlam)[1:32,]
lasso.coef
```
Percent_smokers, percent_uninsured,percent_below_poverty, proTrump, birthrate, GQ estimates, and percent_fair_or_poor_health were the variables that were removed by lasso selection. This led to a cv error of 0.87. 

#GAM

```{r}
mydata<- mydata %>%
  mutate(GQ_ESTIMATES_2019 = GQ_ESTIMATES_2019/total_population)%>%
  mutate(density = total_population/area_sqmi)
```


```{r}
set.seed(1)
train.control <- trainControl(method = "repeatedcv", 
                              number = 10, repeats = 3)
train_data <- mydata[train, ]
test_data <- mydata[-c(train), ]

#lasso selected model
mygam <- gam(covid_death_rate_log ~ s(density) + s(area_sqmi) + s(total_population) +
             s(percentile_rank_social_vulnerability) + s(percent_minorities) +
             s(per_capita_income) + s(lat) + s(lon) + (main_econ) +
               (metro_area) +s(netMigrationRate) +
             s(increaseRate) + s(deathRate) + s(popChange),
             data = train_data, trControl = train.control, method = "REML") 


gam.pred <- predict.gam(mygam, test_data)
mean((gam.pred - test_data$covid_death_rate_log)^2)

mygam <- getViz(mygam)
check(mygam,
      a.qq = list(method = "tnorm", 
                  a.cipoly = list(fill = "light blue")), 
      a.respoi = list(size = 0.5), 
      a.hist = list(bins = 10))
```

Generally, the gam appears to perform better than the lasso. 

```{r forward subsetting}
set.seed(1)

#the forward/reverse subset model
mygam_subset <- gam(covid_death_rate_log ~ s(GQ_ESTIMATES_2019) + s(birthRate) + s(deathRate) +
               s(domMigrationRate) + s(proTrump) + s(lon) + s(lat) + s(per_capita_income) +
               s(percent_below_poverty) + s(percent_minorities) +
                 s(percentile_rank_social_vulnerability) +
               s(percent_uninsured) + s(percent_smokers) + region +
               metro_area + main_econ, data = train_data,
               trControl = train.control, method = "REML") 


gam.pred_subset <- predict.gam(mygam, test_data)
mean((gam.pred_subset - test_data$covid_death_rate_log)^2)
```


However, the forward/backward subset selection does not perform as well as the lasso selection. 


```{r}


morevariable <- gam(covid_death_rate_log ~ GQ_ESTIMATES_2019 + per_capita_income +      percent_minorities + percentile_rank_social_vulnerability + main_econ + metro_area  +  region + per_capita_income * metro_area + percent_minorities * per_capita_income , data = train_data,trControl = train.control, method = "REML")

gam.pred_subset <- predict.gam(morevariable, test_data)
mean((gam.pred_subset - test_data$covid_death_rate_log)^2)
```




